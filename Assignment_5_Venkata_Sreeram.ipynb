{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-5-Venkata Sreeram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOC65LlbR0nWSa42fnZrEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venkata-sreeram-07/ML-Internship/blob/main/Assignment_5_Venkata_Sreeram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znNWUW168rnH"
      },
      "source": [
        "#This is the tutorial of deep learning on FashionMNIST dataset using Pytorch. We will build a Convolutional Neural Network for predicting the classes of Dataset. I am assuming you know the basics of deep leanrning like layer architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgNWrzGA1oJN"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8AMUQE1q3C"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EABtKT9-1_BO"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor()])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0I5QNy2Qk3"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, \n",
        "                                           batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                          batch_size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pM1xU8d2vtp"
      },
      "source": [
        "def output_label(label):\n",
        "    output_mapping = {\n",
        "                 0: \"T-shirt/Top\",\n",
        "                 1: \"Trouser\",\n",
        "                 2: \"Pullover\",\n",
        "                 3: \"Dress\",\n",
        "                 4: \"Coat\", \n",
        "                 5: \"Sandal\", \n",
        "                 6: \"Shirt\",\n",
        "                 7: \"Sneaker\",\n",
        "                 8: \"Bag\",\n",
        "                 9: \"Ankle Boot\"\n",
        "                 }\n",
        "    input = (label.item() if type(label) == torch.Tensor else label)\n",
        "    return output_mapping[input]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7yDpohv24wN"
      },
      "source": [
        "a = next(iter(train_loader))\n",
        "a[0].size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhM3z_8c3GwQ"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv5q4grY3JTn"
      },
      "source": [
        "image, label = next(iter(train_set))\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FTq_49E3LY1"
      },
      "source": [
        "demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
        "\n",
        "batch = next(iter(demo_loader))\n",
        "images, labels = batch\n",
        "print(type(images), type(labels))\n",
        "print(images.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKfHB9X63UfS"
      },
      "source": [
        "grid = torchvision.utils.make_grid(images, nrow=10)\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "print(\"labels: \", end=\" \")\n",
        "for i, label in enumerate(labels):\n",
        "    print(output_label(label), end=\", \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWMHhjZm3q9i"
      },
      "source": [
        "Building a CNN\n",
        "Make a model class (FashionCNN in our case)\n",
        "It inherit nn.Module class that is a super class for all the neural networks in Pytorch.\n",
        "Our Neural Net has following layers:\n",
        "\n",
        "Two Sequential layers each consists of following layers-\n",
        "\n",
        "Convolution layer that has kernel size of 3 * 3, padding = 1 (zero_padding) in 1st layer and padding = 0 in second one. Stride of 1 in both layer.\n",
        "Batch Normalization layer.\n",
        "Acitvation function: ReLU.\n",
        "Max Pooling layer with kernel size of 2 * 2 and stride 2.\n",
        "Flatten out the output for dense layer(a.k.a. fully connected layer).\n",
        "3 Fully connected layer with different in/out features.\n",
        "1 Dropout layer that has class probability p = 0.25.\n",
        "All the functionaltiy is given in forward method that defines the forward pass of CNN.\n",
        "Our input image is changing in a following way:\n",
        "First Convulation layer : input: 28 * 28 * 3, output: 28 * 28 * 32\n",
        "First Max Pooling layer : input: 28 * 28 * 32, output: 14 * 14 * 32\n",
        "Second Conv layer : input : 14 * 14 * 32, output: 12 * 12 * 64\n",
        "Second Max Pooling layer : 12 * 12 * 64, output: 6 * 6 * 64\n",
        "Final fully connected layer has 10 output features for 10 types of clothes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgTRtDbu3Wmd"
      },
      "source": [
        "class FashionCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xz573NL30Sl"
      },
      "source": [
        "Making a model of our CNN class\n",
        "Creating a object(model in the code)\n",
        "Transfering it into GPU if available.\n",
        "Defining a Loss function. we're using CrossEntropyLoss() here.\n",
        "Using Adam algorithm for optimization purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5bLX5Nn3uud"
      },
      "source": [
        "model = FashionCNN()\n",
        "model.to(device)\n",
        "\n",
        "error = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cZo3TUs32I5"
      },
      "source": [
        "num_epochs = 5\n",
        "count = 0\n",
        "# Lists for visualization of loss and accuracy \n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "# Lists for knowing classwise accuracy\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        # Transfering images and labels to GPU if available\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "        train = Variable(images.view(100, 1, 28, 28))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        # Forward pass \n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels)\n",
        "        \n",
        "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Propagating the error backward\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimizing the parameters\n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "    \n",
        "    # Testing the model\n",
        "    \n",
        "        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
        "            total = 0\n",
        "            correct = 0\n",
        "        \n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                labels_list.append(labels)\n",
        "            \n",
        "                test = Variable(images.view(100, 1, 28, 28))\n",
        "            \n",
        "                outputs = model(test)\n",
        "            \n",
        "                predictions = torch.max(outputs, 1)[1].to(device)\n",
        "                predictions_list.append(predictions)\n",
        "                correct += (predictions == labels).sum()\n",
        "            \n",
        "                total += len(labels)\n",
        "            \n",
        "            accuracy = correct * 100 / total\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "        \n",
        "        if not (count % 500):\n",
        "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGqK-6Gx4lFK"
      },
      "source": [
        "##Visualizing Loss Accuracy With Iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnBTUOOV36jA"
      },
      "source": [
        "plt.plot(iteration_list, loss_list)\n",
        "plt.xlabel(\"No. of Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Iterations vs Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMtj_ckh4rku"
      },
      "source": [
        "plt.plot(iteration_list, accuracy_list)\n",
        "plt.xlabel(\"No. of Iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Iterations vs Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y_2zJG_4qSr"
      },
      "source": [
        "##Looking the Accuracy in each class of FashionMNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTCf8Zj_4wb0"
      },
      "source": [
        "class_correct = [0. for _ in range(10)]\n",
        "total_correct = [0. for _ in range(10)]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        test = Variable(images)\n",
        "        outputs = model(test)\n",
        "        predicted = torch.max(outputs, 1)[1]\n",
        "        c = (predicted == labels).squeeze()\n",
        "        \n",
        "        for i in range(100):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            total_correct[label] += 1\n",
        "        \n",
        "for i in range(10):\n",
        "    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 / total_correct[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09nnFgGC42n-"
      },
      "source": [
        "##Printing the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r01Su0F44sZ"
      },
      "source": [
        "from itertools import chain \n",
        "\n",
        "predictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\n",
        "labels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\n",
        "predictions_l = list(chain.from_iterable(predictions_l))\n",
        "labels_l = list(chain.from_iterable(labels_l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZFIKJOk463U"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(labels_l, predictions_l)\n",
        "print(\"Classification report for CNN :\\n%s\\n\"\n",
        "      % (metrics.classification_report(labels_l, predictions_l)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Z7_v578cKO"
      },
      "source": [
        "##This is my implementation of deep learning in FashionMNIST dataset using Pytorch. I've achieved 90.3% test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF15-Ws37tkm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No_OGpmh8qRQ"
      },
      "source": [
        ""
      ]
    }
  ]
}